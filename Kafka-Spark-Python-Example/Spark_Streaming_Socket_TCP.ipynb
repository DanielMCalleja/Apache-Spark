{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Streaming - Socket TCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql.functions import lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)El primer paso es crear una sessión Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PEC2StructuredWordCount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)A continuación, creamos un un Streaming DataFrame que represente los datos de texto recibidos desde un servidor, escuchando en el puerto localhost:9998\n",
    "Para ello abrimos una terminal y ejecutamos el comando -> **nc -lk 9998**\n",
    "El DataFrame **lines** representa una tabla no vinculada conteniendo los datos de texto en streaming. La tabla contiene una columna de cadenas, llamada \"value\", y cada línea en los datos de texto del streaming se convierte en una fila en la tabla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines =spark.readStream.format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 9998).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)El siguiente paso, es convertir el DataFrame en un Dataset, que contenga todas las palabras. Para ello, utilizamos la función split utilizando como separador el espacio. Con la función explode toma el array que contiene las palabras y los separa en múltiples líneas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =lines.select(explode(split(lines.value, \" \")).alias(\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)Una vez obtenidas las palabras, pasamos a realizar un filtrado de estas siguiendo las especificaciones de la práctica.\n",
    "Como primer paso, antes de realizar el filtrado de las palabras, convertimos todos los caracteres de cada palabra a minúscula. El primer filtrado siguiendo las especificaciones será por lo tanto, filtrar las palabras que presentan una longitud menor a 4 caracteres. El segundo filtrado es para las palabras *como, cuando, donde, pero, hasta, mira, mientras* \n",
    "El último filtrado es para las palabras que empiezan por *co*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredWords = words.withColumn('word', lower(col(\"word\"))) \\\n",
    "                     .filter(length(col(\"word\")) > 3) \\\n",
    "                     .filter(~col(\"word\").isin([\"como\",\"cuando\",\"donde\",\"pero\",\"hasta\",\"mira\",\"mientras\"]) ) \\\n",
    "                     .filter(~col(\"word\").startswith('co'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)Una vez filtradas las palabras, definimos un DataFrame agrupando por valores únicos en el DataSet y los contamos. Este Streaming DataFrame representa el word counts en ejecución del stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts =filteredWords.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)Como último paso, preparamos la consulta de los datos del streaming. Utilizamos la opción *outputMode(\"complete\")* para indicarle que imprima en la consola el conjunto completo de recuentos cada vez que se produce una actualización. Y comenzamos la computación del streaming con **start()**\n",
    "Para evitar que el proceso salga mientras la consulta o query esté activa, usamos *awaitTermination()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start running the query that prints the running counts to the console\n",
    "query = wordCounts.writeStream.outputMode(\"complete\").format(\"console\").start()\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
